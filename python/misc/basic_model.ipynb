{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the CSV Data\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load dataset from a CSV file.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# Step 2: Extract Text and Labels\n",
    "def extract_text_and_label(sentiment):\n",
    "    \"\"\"Extract text and label from sentiment column in JSON format.\"\"\"\n",
    "    if isinstance(sentiment, str):\n",
    "        try:\n",
    "            annotations = json.loads(sentiment.replace(\"'\", \"\\\"\"))\n",
    "            if annotations and annotations[0].get(\"labels\"):\n",
    "                text = annotations[0][\"text\"]\n",
    "                label = annotations[0][\"labels\"][0]\n",
    "                return text, label\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "    return None, None\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Apply text and label extraction and remove rows with missing labels.\"\"\"\n",
    "    df[[\"extracted_text\", \"label\"]] = df[\"sentiment\"].apply(lambda x: pd.Series(extract_text_and_label(x)))\n",
    "    df = df.dropna(subset=[\"extracted_text\", \"label\"])\n",
    "    # Map labels to binary values for subjectivity classification (optional)\n",
    "    df[\"label\"] = df[\"label\"].map({\"Neutral\": 0, \"Positive\": 1, \"Negative\": 1})\n",
    "    return df[[\"extracted_text\", \"label\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split_data(df):\n",
    "    \"\"\"Split the data into training and testing sets.\"\"\"\n",
    "    X = df[\"extracted_text\"].tolist()  # Convert to list to avoid indexing issues\n",
    "    y = df[\"label\"].tolist()\n",
    "    \n",
    "    # Perform train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Tokenize Data\n",
    "def tokenize_data(X_train, X_test):\n",
    "    \"\"\"Tokenize the text data for BERT.\"\"\"\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=128)\n",
    "    test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=128)\n",
    "    return train_encodings, test_encodings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Convert to Dataset Class\n",
    "class SubjectivityDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Define Training Arguments\n",
    "def get_training_args():\n",
    "    return TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Train the Model\n",
    "def train_model(X_train, y_train, X_test, y_test):\n",
    "    train_encodings, test_encodings = tokenize_data(X_train, X_test)\n",
    "    train_dataset = SubjectivityDataset(train_encodings, list(y_train))\n",
    "    test_dataset = SubjectivityDataset(test_encodings, list(y_test))\n",
    "\n",
    "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=get_training_args(),\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    trainer.model.save_pretrained(\"./results\")\n",
    "    tokenizer.save_pretrained(\"./results\")\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Evaluate the Model\n",
    "def evaluate_model(trainer):\n",
    "    eval_result = trainer.evaluate()\n",
    "    print(\"Evaluation Results:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(file_path):\n",
    "    # Load and preprocess data\n",
    "    df = load_data(file_path)\n",
    "    processed_df = preprocess_data(df)\n",
    "\n",
    "    # Filter only necessary columns\n",
    "    processed_df = processed_df[[\"extracted_text\", \"label\"]]\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = split_data(processed_df)\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    trainer = train_model(X_train, y_train, X_test, y_test)\n",
    "    evaluate_model(trainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sr/fp0w4m6172z9cylthjqp78l80000gp/T/ipykernel_55303/481303486.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"label\"] = df[\"label\"].map({\"Neutral\": 0, \"Positive\": 1, \"Negative\": 1})\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ffb4561146478d82753a8f6df2db03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3736da1c92124831957be24e4617b474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.26629120111465454, 'eval_accuracy': 0.9655172413793104, 'eval_f1': 0.0, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.3139, 'eval_samples_per_second': 92.392, 'eval_steps_per_second': 6.372, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84a908fbf3043a5a7099d12f37d4eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18545514345169067, 'eval_accuracy': 0.9655172413793104, 'eval_f1': 0.0, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.2933, 'eval_samples_per_second': 98.881, 'eval_steps_per_second': 6.819, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d352e011e9ab4443a9d2e0a0e69f3f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16889667510986328, 'eval_accuracy': 0.9655172413793104, 'eval_f1': 0.0, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.3587, 'eval_samples_per_second': 80.847, 'eval_steps_per_second': 5.576, 'epoch': 3.0}\n",
      "{'train_runtime': 21.9745, 'train_samples_per_second': 15.563, 'train_steps_per_second': 1.092, 'train_loss': 0.3509397506713867, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7baa83a776ee4a06b06cd58d7701dccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.16889667510986328, 'eval_accuracy': 0.9655172413793104, 'eval_f1': 0.0, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.3516, 'eval_samples_per_second': 82.482, 'eval_steps_per_second': 5.688, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "run_pipeline('chunk_0_labelled.csv')  # Replace with your actual file path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sr/fp0w4m6172z9cylthjqp78l80000gp/T/ipykernel_55303/2749924939.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"label\"] = df[\"label\"].map({\"Neutral\": 0, \"Positive\": 1, \"Negative\": 1})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Too often the presenter speaks and the others ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test successful. way to go!!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Randy,\\n\\nCan you send me a schedule of the sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Greg,\\n\\nHow about either next Tuesday or Thur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Please cc the following distribution list with...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>any morning between 10 and 11:30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mr. Buckner,\\n\\nFor delivered gas behind San D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I have been involved in most of the meetings a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Here are the names of the west desk members by...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>35 million is fine</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       extracted_text  label\n",
       "1   Too often the presenter speaks and the others ...      1\n",
       "2                       test successful. way to go!!!      1\n",
       "3   Randy,\\n\\nCan you send me a schedule of the sa...      0\n",
       "5   Greg,\\n\\nHow about either next Tuesday or Thur...      0\n",
       "6   Please cc the following distribution list with...      0\n",
       "7                    any morning between 10 and 11:30      0\n",
       "10  Mr. Buckner,\\n\\nFor delivered gas behind San D...      0\n",
       "13  I have been involved in most of the meetings a...      0\n",
       "14  Here are the names of the west desk members by...      0\n",
       "15                                 35 million is fine      0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path='chunk_0_labelled.csv'\n",
    "df = load_data(file_path)\n",
    "processed_df = preprocess_data(df)\n",
    "\n",
    "# # Split data\n",
    "# X_train, X_test, y_train, y_test = split_data(processed_df)\n",
    "processed_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment for the sample text: Neutral\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the trained model and tokenizer from the output directory\n",
    "model = BertForSequenceClassification.from_pretrained(\"./results\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Define prediction function\n",
    "def predict_sentiment(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "\n",
    "    # Make sure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get the predicted label\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    # Map the predicted class to a label\n",
    "    label_map = {0: \"Neutral\", 1: \"Positive\", 2: \"Negative\"}   # Adjust based on your labels\n",
    "    predicted_label = label_map[predicted_class_id]\n",
    "    \n",
    "    return predicted_label\n",
    "\n",
    "# Test the function with a sample text\n",
    "sample_text = \"this is a waste of time!!\"\n",
    "predicted_label = predict_sentiment(sample_text)\n",
    "print(f\"Predicted Sentiment for the sample text: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
